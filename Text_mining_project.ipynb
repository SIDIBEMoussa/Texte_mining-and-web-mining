{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_mining_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhOfunvvCop9LBkPxNmESf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SIDIBEMoussa/Texte_mining-and-web-mining/blob/main/Text_mining_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3CeeBbsOjx3"
      },
      "source": [
        "link to dataset:\n",
        "https://www.kaggle.com/bittlingmayer/amazonreviews?select=test.ft.txt.bz2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNgCqawrOz8B"
      },
      "source": [
        "Chargement des libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rl3koRx2oEK",
        "outputId": "fd71493e-6dae-4fcb-a870-fc0934d9876c"
      },
      "source": [
        "!pip install fasttext "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFQB49keKmw0"
      },
      "source": [
        "import fasttext\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import bz2\n",
        "import csv\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import os\n",
        "from google.colab import drive"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZaiW-m6O5ka"
      },
      "source": [
        "Connection à drive où son stockés les données de l'étude"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w__nbrFRK4Wn",
        "outputId": "11582281-14bf-42ab-f03f-f05a331552b5"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCokXpXDPFgD"
      },
      "source": [
        "Chargement des données d'études"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esYxlktK5c6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994cc646-f9ec-4ce7-e00d-bd628cc29cd1"
      },
      "source": [
        "data=bz2.BZ2File(\"/content/drive/MyDrive/Text Classification/train.ft.txt.bz2\")\n",
        "data=data.readlines()\n",
        "data=[x.decode('utf-8') for x in data]\n",
        "print(len(data))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3600000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDHwkQxy543X",
        "outputId": "1af8fd02-4e84-4e13-9101-55474cfddccf"
      },
      "source": [
        "data[0:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n',\n",
              " \"__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\n\",\n",
              " '__label__2 Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\\n',\n",
              " \"__label__2 Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\\n\",\n",
              " \"__label__2 Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs5YIzAS56B_"
      },
      "source": [
        "data=pd.DataFrame(data)\n",
        "data.to_csv(\"/content/drive/MyDrive/Text Classification/train.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\" \", escapechar=\" \")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9CiS7dI99Lb",
        "outputId": "de8af5fe-e998-41a3-c89d-3dfbbe3e9149"
      },
      "source": [
        "model = fasttext.train_supervised('/content/drive/MyDrive/Text Classification/train.txt',label_prefix='__label__', thread=4, epoch = 10)\n",
        "print(model.labels, 'are the labels or targets the model is predicting')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__label__1', '__label__2'] are the labels or targets the model is predicting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iph1rdr_Tid",
        "outputId": "9be085fb-794b-4f98-d9ce-b2c8d7ddbc65"
      },
      "source": [
        "test = bz2.BZ2File(\"/content/drive/MyDrive/Text Classification/test.ft.txt.bz2\")\n",
        "test = test.readlines()\n",
        "test = [x.decode('utf-8') for x in test]\n",
        "print(len(test), 'number of records in the test set') \n",
        "\n",
        "# To run the predict function, we need to remove the __label__1 and __label__2 from the testset.  \n",
        "new = [w.replace('__label__2 ', '') for w in test]\n",
        "new = [w.replace('__label__1 ', '') for w in new]\n",
        "new = [w.replace('\\n', '') for w in new]\n",
        "\n",
        "# Use the predict function \n",
        "pred = model.predict(new)\n",
        "\n",
        "# check the first record outputs\n",
        "print(pred[0][0], 'is the predicted label')\n",
        "print(pred[0][1], 'is the probability score')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000 number of records in the test set\n",
            "['__label__2'] is the predicted label\n",
            "['__label__2'] is the probability score\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjEllFwLB4KL",
        "outputId": "db12ad3f-460b-4e31-f65d-5ffe2ba30084"
      },
      "source": [
        "# Lets recode the actual targets to 1's and 0's from both the test set and the actual predictions  \n",
        "labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test]\n",
        "pred_labels = [0 if x == ['__label__1'] else 1 for x in pred[0]]\n",
        "\n",
        "# run the accuracy measure. \n",
        "print(roc_auc_score(labels, pred_labels))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9173499999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TS4vW_OPbNw",
        "outputId": "d07af503-ab58-45d8-9d5b-c9557a8f8ece"
      },
      "source": [
        "data=bz2.BZ2File(\"/content/drive/MyDrive/Text Classification/train.ft.txt.bz2\")\n",
        "data=data.readlines()\n",
        "data=[x.decode('utf-8') for x in data]\n",
        "print(len(data))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3600000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbh6jCmxQQkI",
        "outputId": "d0f99332-0502-4540-8a59-cf865af58a70"
      },
      "source": [
        "data=pd.DataFrame(data)\n",
        "data.head()\n",
        "train_size=int(0.70*len(data))\n",
        "train_size"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2520000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpZB_Y16PW4l"
      },
      "source": [
        "data[:train_size].to_csv(\"/content/drive/MyDrive/Text Classification/train_op.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\" \", escapechar=\" \")\n",
        "data[train_size:].to_csv(\"/content/drive/MyDrive/Text Classification/validation_op.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\" \", escapechar=\" \")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "6nXmak0TCCEs",
        "outputId": "1f37f394-e826-4f03-9fc3-5c58f2218315"
      },
      "source": [
        "model1 = fasttext.train_supervised(\n",
        "    input='/content/drive/MyDrive/Text Classification/train_op.txt',\n",
        "    autotuneValidationFile='/content/drive/MyDrive/Text Classification/validation_op.txt',\n",
        "    label_prefix='__label__',\n",
        "     thread=4, epoch = 10)\n",
        "print(model1.labels, 'are the labels or targets the model is predicting')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d056e93c6625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mautotuneValidationFile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Text Classification/validation_op.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabel_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'__label__'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m      thread=4, epoch = 10)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'are the labels or targets the model is predicting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fasttext/FastText.py\u001b[0m in \u001b[0;36mtrain_supervised\u001b[0;34m(*kargs, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanually_set_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m     \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m     \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Didn't have enough time to train once: please increase `autotune-duration`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wODgCCaFRhew"
      },
      "source": [
        "# Use the predict function \n",
        "pred = model1.predict(new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXRPsgXsR9d4"
      },
      "source": [
        "# Lets recode the actual targets to 1's and 0's from both the test set and the actual predictions  \n",
        "labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test]\n",
        "pred_labels = [0 if x == ['__label__1'] else 1 for x in pred[0]]\n",
        "\n",
        "# run the accuracy measure. \n",
        "print(roc_auc_score(labels, pred_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPxqOLrYSe8T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}